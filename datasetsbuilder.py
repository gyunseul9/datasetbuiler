# -*- coding: utf-8 -*-
"""datasetsBuilder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hr0GuGL8aetfCR5R6qFFrLabQu3QCOC3
"""

import os
import glob
import shutil
import numpy as np
import pandas as pd
from google.colab import drive

c=drive.mount('/content/drive')

np.random.seed(42)

TRAIN_CSV = 'drive/My Drive/development/dataset/aptos2019/train.csv'
TRAIN_IMG = 'drive/My Drive/development/images/aptos2019/train_images/'
TRAIN_EXE = '.png'

TRAIN_DIR = 'drive/My Drive/development/colab/AIPlatform/multi_prototype/training_data'
VAL_DIR = 'drive/My Drive/development/colab/AIPlatform/multi_prototype/validation_data'
TEST_DIR = 'drive/My Drive/development/colab/AIPlatform/multi_prototype/test_data'

def log_progress(sequence, every=None, size=None, name='Items'):
    from ipywidgets import IntProgress, HTML, VBox
    from IPython.display import display

    is_iterator = False
    if size is None:
        try:
            size = len(sequence)
        except TypeError:
            is_iterator = True
    if size is not None:
        if every is None:
            if size <= 200:
                every = 1
            else:
                every = int(size / 200)     # every 0.5%
    else:
        assert every is not None, 'sequence is iterator, set every'

    if is_iterator:
        progress = IntProgress(min=0, max=1, value=1)
        progress.bar_style = 'info'
    else:
        progress = IntProgress(min=0, max=size, value=0)
    label = HTML()
    box = VBox(children=[label, progress])
    display(box)

    index = 0
    try:
        for index, record in enumerate(sequence, 1):
            if index == 1 or index % every == 0:
                if is_iterator:
                    label.value = '{name}: {index} / ?'.format(
                        name=name,
                        index=index
                    )
                else:
                    progress.value = index
                    label.value = u'{name}: {index} / {size}'.format(
                        name=name,
                        index=index,
                        size=size
                    )
            yield record
    except:
        progress.bar_style = 'danger'
        raise
    else:
        progress.bar_style = 'success'
        progress.value = index
        label.value = "{name}: {index}".format(
            name=name,
            index=str(index or '?')
        )

def extract_filename(dirs):
  tmp = []
  tmp = dirs.split('/')
  
  tmp2 = tmp[len(tmp)-1]
  value = tmp2.split('.')[0].strip()

  return value

def extract_csv(filename):

  data = pd.read_csv(TRAIN_CSV, header=None)
  result = data.loc[data.iloc[:,0].str.contains(filename, na=False)]
  value = result.iloc[:, 0].values[0] + ':' + result.iloc[:, 1].values[0]
  return value

files = glob.glob(TRAIN_IMG+'*')

print(len(files))

nodr_files, mild_files, mode_files, seve_files, prol_files = [], [], [], [], []

for i in files:
  name = extract_csv(extract_filename(i)).split(':')[0].strip()
  label = extract_csv(extract_filename(i)).split(':')[1].strip()

  if label == '0':
    nodr_files.append(TRAIN_IMG+name+TRAIN_EXE)
  elif label == '1':
    mild_files.append(TRAIN_IMG+name+TRAIN_EXE)
  elif label == '2':
    mode_files.append(TRAIN_IMG+name+TRAIN_EXE)
  elif label == '3':
    seve_files.append(TRAIN_IMG+name+TRAIN_EXE)
  elif label == '4':
    prol_files.append(TRAIN_IMG+name+TRAIN_EXE) 

print(len(nodr_files),len(mild_files),len(mode_files),len(seve_files),len(prol_files))
print(len(nodr_files)+len(mild_files)+len(mode_files)+len(seve_files)+len(prol_files))
print(prol_files)

#100개 이상 생성 에러 발생
nodr_train = np.random.choice(nodr_files, size=190, replace=True)
mild_train = np.random.choice(mild_files, size=190, replace=True)
mode_train = np.random.choice(mode_files, size=190, replace=True)
seve_train = np.random.choice(seve_files, size=190, replace=True)
prol_train = np.random.choice(prol_files, size=190, replace=True)

nodr_files = list(set(nodr_files) - set(nodr_train))
mild_files = list(set(mild_files) - set(mild_train))
mode_files = list(set(mode_files) - set(mode_train))
seve_files = list(set(seve_files) - set(seve_train))
prol_files = list(set(prol_files) - set(prol_train))

nodr_val = np.random.choice(nodr_files, size=190, replace=True)
mild_val = np.random.choice(mild_files, size=190, replace=True)
mode_val = np.random.choice(mode_files, size=190, replace=True)
seve_val = np.random.choice(seve_files, size=190, replace=True)
prol_val = np.random.choice(prol_files, size=190, replace=True)

nodr_files = list(set(nodr_files) - set(nodr_val))
mild_files = list(set(mild_files) - set(mild_val))
mode_files = list(set(mode_files) - set(mode_val))
seve_files = list(set(seve_files) - set(seve_val))
prol_files = list(set(prol_files) - set(prol_val))

nodr_test = np.random.choice(nodr_files, size=190, replace=True)
mild_test = np.random.choice(mild_files, size=190, replace=True)
mode_test = np.random.choice(mode_files, size=190, replace=True)
seve_test = np.random.choice(seve_files, size=190, replace=True)
prol_test = np.random.choice(prol_files, size=190, replace=True)

print('No DR datasets:', nodr_train.shape, nodr_val.shape, nodr_test.shape)
print('Mild datasets:', mild_train.shape, mild_val.shape, mild_test.shape)
print('Moderate datasets:', mode_train.shape, mode_val.shape, mode_test.shape)
print('Severe datasets:', seve_train.shape, seve_val.shape, seve_test.shape)
print('Proliferative datasets:', prol_train.shape, prol_val.shape, prol_test.shape)

train_files = np.concatenate([nodr_train, mild_train, mode_train, seve_train, prol_train])
validate_files = np.concatenate([nodr_val, mild_val, mode_val, seve_val, prol_val])
test_files = np.concatenate([nodr_train, mild_train, mode_train, seve_train, prol_train])

os.mkdir(TRAIN_DIR) if not os.path.isdir(TRAIN_DIR) else None
os.mkdir(VAL_DIR) if not os.path.isdir(VAL_DIR) else None
os.mkdir(TEST_DIR) if not os.path.isdir(TEST_DIR) else None

for fn in log_progress(train_files, name='Training Images'):
    shutil.copy(fn, TRAIN_DIR)

for fn in log_progress(validate_files, name='Validation Images'):
    shutil.copy(fn, VAL_DIR)
    
for fn in log_progress(test_files, name='Test Images'):
    shutil.copy(fn, TEST_DIR)

